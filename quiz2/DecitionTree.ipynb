{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "包含两个元素：\n",
    "1. decision\n",
    "2. subNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **初始化条件**：`DTNode`对象在初始化时必须接受一个`decision`参数，这个参数有两种可能的形式：\n",
    "   - 一个函数：它接收一个对象（通常是一个特征向量），并指示应该跟随哪个子节点（当该对象是决策节点时）。\n",
    "   - 一个值：代表分类或回归的结果（当对象是叶节点时）。\n",
    "\n",
    "2. **子节点管理**：`DTNode`对象必须有一个名为`children`的属性，这个属性被设置为一个数据结构，它映射决策函数的输出到一个特定的子节点。我们假设决策函数的输出是一个索引，指向一个列表。\n",
    "\n",
    "3. **预测方法**：`DTNode`还必须有一个名为`predict`的方法，它接收一个输入对象（例如，一个特征向量），并返回该输入在决策树中的结果。\n",
    "\n",
    "**提示**：`predict`方法是递归的。你可以使用内置函数`callable`来测试一个Python对象是否可调用（在这种情况下是一个函数）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "    # def __init__(self, func):\n",
    "    def init(self, func):\n",
    "        self.func = func  # 将传入的函数赋值给一个实例变量\n",
    "    # arguments ; keyword arguments\n",
    "    \n",
    "    def call_func(self, *args, **kwargs):\n",
    "        # 调用存储的函数，并传递任何参数\n",
    "        return self.func(*args, **kwargs)\n",
    "    \n",
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "# 创建 MyClass 的实例，将 greet 函数作为参数传递\n",
    "my_instance = MyClass()\n",
    "my_instance.init(greet)\n",
    "\n",
    "# 通过 MyClass 实例调用传入的 greet 函数\n",
    "print(my_instance.call_func(\"World\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class as Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "class ConsumerClass:\n",
    "    def __init__(self, class_input):\n",
    "        self.class_input = class_input  # 将传入的类赋值给一个实例变量\n",
    "    \n",
    "    def create_instance(self, *args, **kwargs):\n",
    "        # 使用传入的类创建一个实例，并传递任何初始化参数\n",
    "        return self.class_input(*args, **kwargs)\n",
    "    \n",
    "    \n",
    "class Greeter:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def greet(self):\n",
    "        return f\"Hello, {self.name}!\"\n",
    "\n",
    "# 创建 ConsumerClass 的实例，将 Greeter 类作为参数传递\n",
    "consumer_instance = ConsumerClass(Greeter)\n",
    "\n",
    "# 通过 ConsumerClass 实例创建 Greeter 的一个实例\n",
    "greeter_instance = consumer_instance.create_instance(\"World\")\n",
    "\n",
    "# 调用 greeter_instance 的 greet 方法\n",
    "print(greeter_instance.greet())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.decision callable\n",
      "child_index  1\n",
      "self_index  2\n",
      "The decision is  No\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "class DTNode:\n",
    "    def __init__(self, decision):\n",
    "        self.decision = decision\n",
    "        self.children = []\n",
    "\n",
    "    def predict(self, input_obj):\n",
    "        if callable(self.decision):\n",
    "            print(\"self.decision callable\")\n",
    "            \n",
    "            child_index = self.decision(input_obj)\n",
    "            print(\"child_index \" , child_index)\n",
    "            print(\"self_index \" , len(self.children))\n",
    "            \n",
    "            if child_index < len(self.children):\n",
    "                return self.children[child_index].predict(input_obj)\n",
    "            else:\n",
    "                raise ValueError(\"Error\")\n",
    "        else:\n",
    "            print(\"The decision is \",self.decision)\n",
    "            return self.decision\n",
    "\n",
    "# ==================== TEST CASE ====================\n",
    "\n",
    "yes_node = DTNode(\"Yes\")\n",
    "no_node = DTNode(\"No\")\n",
    "tree_root = DTNode(lambda x: 0 if x[2] < 4 else 1)\n",
    "tree_root.children = [yes_node, no_node]\n",
    "\n",
    "# print(tree_root.predict((False, 'Red', 3.5)))\n",
    "print(tree_root.predict((False, 'Green', 6.1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class DTNode:\n",
    "    def __init__(self, decision):\n",
    "        self.decision = decision\n",
    "        self.children = []\n",
    "\n",
    "    def predict(self, input_obj):\n",
    "        if callable(self.decision):\n",
    "            print(\"self.decision callable\")\n",
    "            \n",
    "            child_index = self.decision(input_obj)\n",
    "            print(\"child_index \" , child_index)\n",
    "            print(\"self_index \" , len(self.children))\n",
    "            \n",
    "            if child_index < len(self.children):\n",
    "                return self.children[child_index].predict(input_obj)\n",
    "            else:\n",
    "                raise ValueError(\"Error\")\n",
    "        else:\n",
    "            print(\"The decision is \",self.decision)\n",
    "            return self.decision\n",
    "        \n",
    "    def leaves(self):\n",
    "        if not callable(self.decision):\n",
    "            return 1\n",
    "        else:\n",
    "            return sum(child.leaves() for child in self.children)\n",
    "            # print(\"more\")\n",
    "\n",
    "# ==================== TEST CASE ====================\n",
    "\t\n",
    "t = DTNode(True)\n",
    "f = DTNode(False)\n",
    "n = DTNode(lambda v: 0 if not v else 1)\n",
    "n.children = [t, f]\n",
    "print(n.leaves())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_by_feature_value(dataset, feature_index):\n",
    "    partitions = {}\n",
    "    for x, y in dataset:\n",
    "        key = x[feature_index]\n",
    "        print(\"Key: \",key)\n",
    "        \n",
    "        print(\"Partitions: \")\n",
    "        for _ in partitions:\n",
    "            print(_)\n",
    "\n",
    "        if key not in partitions:\n",
    "            partitions[key] = []\n",
    "        partitions[key].append((x, y))\n",
    "    \n",
    "    # 将分区映射转换为列表，以便通过索引访问\n",
    "    partition_list = list(partitions.values())\n",
    "    \n",
    "    # 定义分隔器函数\n",
    "    def separator(feature_vector):\n",
    "        return list(partitions.keys()).index(feature_vector[feature_index])\n",
    "    \n",
    "    return separator, partition_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[((False, False), False), ((False, True), True)],\n",
      " [((True, False), True), ((True, True), False)]]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ------------- TEST \n",
    "from pprint import pprint\n",
    "dataset = [\n",
    "  ((True, True), False),\n",
    "  ((True, False), True),\n",
    "  ((False, True), True),\n",
    "  ((False, False), False),\n",
    "]\n",
    "f, p = partition_by_feature_value(dataset,  0)\n",
    "pprint(sorted(sorted(partition) for partition in p))\n",
    "\n",
    "partition_index = f((True, True))\n",
    "# Everything in the \"True\" partition for feature 0 is true\n",
    "print(all(x[0]==True for x,c in p[partition_index]))\n",
    "partition_index = f((False, True))\n",
    "# Everything in the \"False\" partition for feature 0 is false\n",
    "print(all(x[0]==False for x,c in p[partition_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  a\n",
      "Partitions: \n",
      "Key:  b\n",
      "Partitions: \n",
      "a\n",
      "Key:  a\n",
      "Partitions: \n",
      "a\n",
      "b\n",
      "Key:  c\n",
      "Partitions: \n",
      "a\n",
      "b\n",
      "separator: \n",
      "<function partition_by_feature_value.<locals>.separator at 0x12213d4e0>\n",
      "\n",
      "Partition_List\n",
      "[[(('a', 'x', 2), False), (('a', 'y', 5), True)], [(('b', 'x', 2), False)], [(('c', 'y', 5), False)]]\n",
      "[[(('a', 'x', 2), False), (('a', 'y', 5), True)],\n",
      " [(('b', 'x', 2), False)],\n",
      " [(('c', 'y', 5), False)]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ------ test 2\n",
    "\n",
    "from pprint import pprint\n",
    "dataset = [\n",
    "  ((\"a\", \"x\", 2), False),\n",
    "  ((\"b\", \"x\", 2), False),\n",
    "  ((\"a\", \"y\", 5), True),\n",
    "  ((\"c\", \"y\", 5), False),\n",
    "]\n",
    "f, p = partition_by_feature_value(dataset, 0)\n",
    "print(\"separator: \")\n",
    "print(f)\n",
    "print(\"\\nPartition_List\")\n",
    "print(p)\n",
    "pprint(sorted(sorted(partition) for partition in p))\n",
    "partition_index = f((\"a\", \"y\", 5))\n",
    "# everything in the \"y\" partition for feature 1 has a y\n",
    "print(all(x[0]==\"a\" for x, c in p[partition_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000\n",
      "0.5000\n",
      "1.0000\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "\n",
    "def calculate_proportions(dataset):\n",
    "    counts = {}\n",
    "    for _, classification in dataset:\n",
    "        counts[classification] = counts.get(classification, 0) + 1\n",
    "    total = len(dataset)\n",
    "    proportions = {k: v / total for k, v in counts.items()}\n",
    "    return proportions.values()\n",
    "\n",
    "def misclassification(dataset):\n",
    "    proportions = calculate_proportions(dataset)\n",
    "    return 1 - max(proportions)\n",
    "\n",
    "def gini(dataset):\n",
    "    proportions = calculate_proportions(dataset)\n",
    "    return sum(p * (1 - p) for p in proportions)\n",
    "\n",
    "def entropy(dataset):\n",
    "    proportions = calculate_proportions(dataset)\n",
    "    return -sum(p * log2(p) for p in proportions if p > 0)\n",
    "\n",
    "# 用于测试的数据集\n",
    "data = [\n",
    "    ((False, False), False),\n",
    "    ((False, True), True),\n",
    "    ((True, False), True),\n",
    "    ((True, True), False)\n",
    "]\n",
    "\n",
    "# 执行测试并打印结果\n",
    "data = [\n",
    "    ((False, False), False),\n",
    "    ((False, True), True),\n",
    "    ((True, False), True),\n",
    "    ((True, True), False)\n",
    "]\n",
    "print(\"{:.4f}\".format(misclassification(data)))\n",
    "print(\"{:.4f}\".format(gini(data)))\n",
    "print(\"{:.4f}\".format(entropy(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNode:\n",
    "    def __init__(self, decision=None, label=None):\n",
    "        self.decision = decision  # Can be a callable (for decision nodes) or None (for leaf nodes)\n",
    "        self.label = label  # Used for leaf nodes\n",
    "        self.children = {}  # Maps feature values to DTNode instances\n",
    "\n",
    "    def predict(self, input_obj):\n",
    "        if self.decision is None:\n",
    "            return self.label\n",
    "        else:\n",
    "            feature_value = self.decision(input_obj)\n",
    "            if feature_value in self.children:\n",
    "                return self.children[feature_value].predict(input_obj)\n",
    "            else:\n",
    "                return None  # Or some default prediction\n",
    "\n",
    "def partition_by_feature_value(dataset, feature_index):\n",
    "    partitions = {}\n",
    "    for x, y in dataset:\n",
    "        key = x[feature_index]\n",
    "        if key not in partitions:\n",
    "            partitions[key] = []\n",
    "        partitions[key].append((x, y))\n",
    "\n",
    "    partition_list = list(partitions.values())\n",
    "\n",
    "    def separator(feature_vector):\n",
    "        return list(partitions.keys()).index(feature_vector[feature_index])\n",
    "\n",
    "    return separator, partition_list\n",
    "\n",
    "def misclassification(dataset):\n",
    "    proportions = calculate_proportions(dataset)\n",
    "    return 1 - max(proportions)\n",
    "# def misclassification(dataset):\n",
    "#     proportions = calculate_proportions(dataset)\n",
    "#     return 1 - max(proportions.values())\n",
    "def calculate_proportions(dataset):\n",
    "    \"\"\"Calculate the proportions of each classification in the dataset.\"\"\"\n",
    "    counts = {}\n",
    "    for _, classification in dataset:\n",
    "        counts[classification] = counts.get(classification, 0) + 1\n",
    "    total = len(dataset)\n",
    "    return {k: v / total for k, v in counts.items()}\n",
    "\n",
    "\n",
    "def train_tree(dataset, criterion, depth=0):\n",
    "    # Base case: if all examples have the same classification, return a leaf node\n",
    "    if len(set(y for _, y in dataset)) == 1:\n",
    "        return DTNode(label=dataset[0][1])\n",
    "\n",
    "    # Choose the best feature to split on\n",
    "    num_features = len(dataset[0][0])\n",
    "    best_feature, best_impurity = None, float('inf')\n",
    "    for feature_index in range(num_features):\n",
    "        _, partitions = partition_by_feature_value(dataset, feature_index)\n",
    "        impurity = sum(criterion(part) for part in partitions)\n",
    "        if impurity < best_impurity:\n",
    "            best_feature, best_impurity = feature_index, impurity\n",
    "\n",
    "    if best_feature is None:\n",
    "        # Return a leaf node with the most common label if no improvement can be made\n",
    "        labels = [y for _, y in dataset]\n",
    "        most_common_label = max(set(labels), key=labels.count)\n",
    "        return DTNode(label=most_common_label)\n",
    "\n",
    "    # Partition the dataset by the best feature and create child nodes\n",
    "    separator, partitions = partition_by_feature_value(dataset, best_feature)\n",
    "    node = DTNode(decision=lambda x: x[best_feature])\n",
    "    for i, partition in enumerate(partitions):\n",
    "        child = train_tree(partition, criterion, depth + 1)\n",
    "        node.children[list(separator.keys())[i]] = child\n",
    "\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 77\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m# Example Test\u001b[39;00m\n\u001b[1;32m     71\u001b[0m dataset \u001b[39m=\u001b[39m [\n\u001b[1;32m     72\u001b[0m   ((\u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m), \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     73\u001b[0m   ((\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m), \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     74\u001b[0m   ((\u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m), \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     75\u001b[0m   ((\u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m), \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m ]\n\u001b[0;32m---> 77\u001b[0m t \u001b[39m=\u001b[39m train_tree(dataset, misclassification)\n\u001b[1;32m     78\u001b[0m \u001b[39mprint\u001b[39m(t\u001b[39m.\u001b[39mpredict((\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)))  \u001b[39m# Expected: True\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(t\u001b[39m.\u001b[39mpredict((\u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)))  \u001b[39m# Expected: False\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 65\u001b[0m, in \u001b[0;36mtrain_tree\u001b[0;34m(dataset, criterion, depth)\u001b[0m\n\u001b[1;32m     63\u001b[0m node \u001b[39m=\u001b[39m DTNode(decision\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[best_feature])\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m i, partition \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(partitions):\n\u001b[0;32m---> 65\u001b[0m     child \u001b[39m=\u001b[39m train_tree(partition, criterion, depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     66\u001b[0m     node\u001b[39m.\u001b[39mchildren[\u001b[39mlist\u001b[39m(partitions\u001b[39m.\u001b[39mkeys())[i]] \u001b[39m=\u001b[39m child\n\u001b[1;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "Cell \u001b[0;32mIn[60], line 66\u001b[0m, in \u001b[0;36mtrain_tree\u001b[0;34m(dataset, criterion, depth)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m i, partition \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(partitions):\n\u001b[1;32m     65\u001b[0m     child \u001b[39m=\u001b[39m train_tree(partition, criterion, depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     node\u001b[39m.\u001b[39mchildren[\u001b[39mlist\u001b[39m(partitions\u001b[39m.\u001b[39;49mkeys())[i]] \u001b[39m=\u001b[39m child\n\u001b[1;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "\n",
    "class DTNode:\n",
    "    def __init__(self, decision=None, label=None):\n",
    "        self.decision = decision  # Can be a callable (for decision nodes) or None (for leaf nodes)\n",
    "        self.label = label  # Used for leaf nodes\n",
    "        self.children = {}  # Maps feature values to DTNode instances\n",
    "\n",
    "    def predict(self, input_obj):\n",
    "        if self.decision is None:\n",
    "            return self.label\n",
    "        else:\n",
    "            feature_value = self.decision(input_obj)\n",
    "            if feature_value in self.children:\n",
    "                return self.children[feature_value].predict(input_obj)\n",
    "            else:\n",
    "                return None  # Or some default prediction\n",
    "\n",
    "def calculate_proportions(dataset):\n",
    "    counts = {}\n",
    "    for _, classification in dataset:\n",
    "        counts[classification] = counts.get(classification, 0) + 1\n",
    "    total = len(dataset)\n",
    "    return {k: v / total for k, v in counts.items()}\n",
    "\n",
    "def misclassification(dataset):\n",
    "    proportions = calculate_proportions(dataset)\n",
    "    return 1 - max(proportions.values())\n",
    "\n",
    "def partition_by_feature_value(dataset, feature_index):\n",
    "    partitions = {}\n",
    "    for x, y in dataset:\n",
    "        key = x[feature_index]\n",
    "        if key not in partitions:\n",
    "            partitions[key] = []\n",
    "        partitions[key].append((x, y))\n",
    "\n",
    "    partition_list = list(partitions.values())\n",
    "\n",
    "    def separator(feature_vector):\n",
    "        return list(partitions.keys()).index(feature_vector[feature_index])\n",
    "\n",
    "    return separator, partition_list\n",
    "\n",
    "def train_tree(dataset, criterion, depth=0):\n",
    "    if len(set(y for _, y in dataset)) == 1:\n",
    "        return DTNode(label=dataset[0][1])\n",
    "\n",
    "    num_features = len(dataset[0][0])\n",
    "    best_feature, best_impurity = None, float('inf')\n",
    "    for feature_index in range(num_features):\n",
    "        _, partitions = partition_by_feature_value(dataset, feature_index)\n",
    "        impurity = sum(criterion(part) for part in partitions)\n",
    "        if impurity < best_impurity:\n",
    "            best_feature, best_impurity = feature_index, impurity\n",
    "\n",
    "    if best_feature is None:\n",
    "        labels = [y for _, y in dataset]\n",
    "        most_common_label = max(set(labels), key=labels.count)\n",
    "        return DTNode(label=most_common_label)\n",
    "\n",
    "    separator, partitions = partition_by_feature_value(dataset, best_feature)\n",
    "    node = DTNode(decision=lambda x: x[best_feature])\n",
    "    for i, partition in enumerate(partitions):\n",
    "        child = train_tree(partition, criterion, depth + 1)\n",
    "        node.children[list(partitions.keys())[i]] = child\n",
    "\n",
    "    return node\n",
    "\n",
    "# Example Test\n",
    "dataset = [\n",
    "  ((True, True), False),\n",
    "  ((True, False), True),\n",
    "  ((False, True), True),\n",
    "  ((False, False), False)\n",
    "]\n",
    "t = train_tree(dataset, misclassification)\n",
    "print(t.predict((True, False)))  # Expected: True\n",
    "print(t.predict((False, False)))  # Expected: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "  ((True, True), False),\n",
    "  ((True, False), True),\n",
    "  ((False, True), True),\n",
    "  ((False, False), False)\n",
    "]\n",
    "t = train_tree(dataset, misclassification)\n",
    "print(t.predict((True, False)))\n",
    "print(t.predict((False, False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def partition_by_feature_value(dataset, feature_index):\n",
    "    partitions = {}\n",
    "    for features, label in dataset:\n",
    "        feature_value = features[feature_index]\n",
    "        if feature_value not in partitions:\n",
    "            partitions[feature_value] = []\n",
    "        partitions[feature_value].append((features, label))\n",
    "    return partitions\n",
    "\n",
    "class DTNode:\n",
    "    def __init__(self, decision=None, label=None):\n",
    "        self.decision = decision  # Function for decision nodes\n",
    "        self.label = label  # Label for leaf nodes\n",
    "        self.children = {}  # Children nodes\n",
    "\n",
    "    def predict(self, input_obj):\n",
    "        if self.decision is None:  # Leaf node\n",
    "            return self.label\n",
    "        else:  # Decision node\n",
    "            feature_value = self.decision(input_obj)\n",
    "            if feature_value in self.children:\n",
    "                return self.children[feature_value].predict(input_obj)\n",
    "            return None\n",
    "\n",
    "def train_tree(dataset, criterion, feature_index=0, depth=0):\n",
    "    # Base case: if all examples have the same classification or no features left\n",
    "    classifications = [y for _, y in dataset]\n",
    "    if len(set(classifications)) == 1:\n",
    "        return DTNode(label=classifications[0])\n",
    "\n",
    "    # Find the best feature to split on\n",
    "    best_feature = feature_index  # Simplified; in practice, you might evaluate each feature\n",
    "\n",
    "    partitions = partition_by_feature_value(dataset, best_feature)\n",
    "\n",
    "    # Decision node based on the best feature; adjust if evaluating best feature\n",
    "    node = DTNode(decision=lambda x: x[best_feature])\n",
    "    for feature_value, partition in partitions.items():\n",
    "        if len(partition) > 0:\n",
    "            # Recursively build the tree\n",
    "            child = train_tree(partition, criterion, feature_index + 1, depth + 1)\n",
    "            node.children[feature_value] = child\n",
    "        else:\n",
    "            # Handle empty partition if necessary\n",
    "            pass\n",
    "\n",
    "    return node\n",
    "def misclassification(dataset):\n",
    "    proportions = calculate_proportions(dataset)\n",
    "    return 1 - max(proportions.values())\n",
    "\n",
    "dataset = [\n",
    "  ((True, True), False),\n",
    "  ((True, False), True),\n",
    "  ((False, True), True),\n",
    "  ((False, False), False)\n",
    "]\n",
    "t = train_tree(dataset, misclassification)\n",
    "print(t.predict((True, False)))\n",
    "print(t.predict((False, False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 64-bit ('3.12.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49a2be796fb9d467b4a32eeffd280e817abf000e884f8f05778a9b063df0518a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
